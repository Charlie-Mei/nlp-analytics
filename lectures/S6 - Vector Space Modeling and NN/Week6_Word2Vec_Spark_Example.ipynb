{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 2.4.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext() \n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "\n",
    "print(\"Using Apache Spark Version\", sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load( disable=['parser', 'tagger','ner'] )\n",
    "\n",
    "def cleanup_pretokenize(text):\n",
    "    #text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.replace(\"'s\", \" \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.replace(\"'ve\", \" have \")\n",
    "    text = text.replace(\"'re\", \" are \")\n",
    "    text = text.replace(\"I'm\",\" I am \")\n",
    "    text = text.replace(\"you're\",\" you are \")\n",
    "    text = text.replace(\"You're\",\" You are \")\n",
    "    text = text.replace(\"-\",\" \")\n",
    "    text = text.replace(\"/\",\" \")\n",
    "    text = text.replace(\"(\",\" \")\n",
    "    text = text.replace(\")\",\" \")\n",
    "    text = text.replace(\"%\",\" percent \")\n",
    "    return text\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def text_cleanup(row):\n",
    "    desc = row[2].strip().lower()\n",
    "    tokens = [w.lemma_ for w in nlp(cleanup_pretokenize(desc))]\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if len(token) > 3]\n",
    "    #tokens = [lmtzr.lemmatize(token,'v') for token in tokens]\n",
    "    row[2] = ' '.join(tokens)\n",
    "    return row\n",
    "\n",
    "regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'description', outputCol = 'tokens')\n",
    "swr = StopWordsRemover(inputCol = 'tokens', outputCol = 'tokens_sw_removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunchbase_df = sqlContext.read.option(\"header\", \"true\").option(\"delimiter\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .csv(\"/Users/javid/projects/enaibl/data/cb_odm_092419.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunchbase_data = crunchbase_df['crunchbase_uuid','name','short_description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+\n",
      "|     crunchbase_uuid|    name|         description|\n",
      "+--------------------+--------+--------------------+\n",
      "|e1393508-30ea-8a3...|Wetpaint|Wetpaint offers a...|\n",
      "|bf4d7b0e-b34d-2fd...|    Zoho|Zoho offers a sui...|\n",
      "|5f2b40b8-d1b3-d32...|    Digg|Digg Inc. operate...|\n",
      "|df662812-7f97-0b4...|Facebook|Facebook is an on...|\n",
      "|b08efc27-da40-505...|   Accel|Accel is an early...|\n",
      "+--------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crunchbase_columns = [0,1,2]\n",
    "crunchbase_rdd = crunchbase_data.select('*') \\\n",
    "                       .rdd.map(lambda row: [row[i] for i in crunchbase_columns]) \\\n",
    "                       .filter(lambda row: row[2] is not None)\n",
    "crunchbase_df = sqlContext.createDataFrame(crunchbase_rdd, \n",
    "                                           ['crunchbase_uuid','name','description'])\n",
    "crunchbase_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / (np.sqrt(np.dot(v2, v2))+.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|     crunchbase_uuid|    name|         description|              tokens|   tokens_sw_removed|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|e1393508-30ea-8a3...|Wetpaint|Wetpaint offers a...|[wetpaint, offers...|[wetpaint, offers...|\n",
      "|bf4d7b0e-b34d-2fd...|    Zoho|Zoho offers a sui...|[zoho, offers, a,...|[zoho, offers, su...|\n",
      "|5f2b40b8-d1b3-d32...|    Digg|Digg Inc. operate...|[digg, inc, opera...|[digg, inc, opera...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tokens = regexTokenizer.transform(crunchbase_df)\n",
    "desc_swr = swr.transform(df_tokens)\n",
    "desc_swr.show(3)\n",
    "#desc_swr_half = desc_swr.limit(50000)\n",
    "#desc_swr_half.show(3)\n",
    "#desc_swr.write.saveAsTable('desc_swr', mode = 'overwrite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+\n",
      "|     crunchbase_uuid|    name|         wordvectors|\n",
      "+--------------------+--------+--------------------+\n",
      "|e1393508-30ea-8a3...|Wetpaint|[-0.0655311768253...|\n",
      "|bf4d7b0e-b34d-2fd...|    Zoho|[-0.0572017064717...|\n",
      "|5f2b40b8-d1b3-d32...|    Digg|[-0.0059538231446...|\n",
      "|df662812-7f97-0b4...|Facebook|[0.04988502562046...|\n",
      "|b08efc27-da40-505...|   Accel|[-0.0774579850787...|\n",
      "+--------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(vectorSize = 300, minCount = 5, inputCol = 'tokens_sw_removed', outputCol = 'wordvectors')\n",
    "model = word2vec.fit(desc_swr)\n",
    "wordvectors = model.transform(desc_swr)\n",
    "#wordvectors.select('wordvectors').show(1, truncate = True)\n",
    "crunchbase_desc = wordvectors.select('crunchbase_uuid','name','wordvectors').rdd.toDF()\n",
    "crunchbase_desc.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     word|        similarity|\n",
      "+---------+------------------+\n",
      "|instagram|0.7966665625572205|\n",
      "|  twitter|0.7834885120391846|\n",
      "| linkedin|0.7453723549842834|\n",
      "|pinterest|0.6593936085700989|\n",
      "|followers|0.6581313610076904|\n",
      "|     bing|0.6570589542388916|\n",
      "|   google|0.6495094299316406|\n",
      "|       fb|0.6432822346687317|\n",
      "| whatsapp|0.6388134956359863|\n",
      "|    pages|0.6143272519111633|\n",
      "| snapchat|0.6061036586761475|\n",
      "|    slack|0.6059338450431824|\n",
      "|    yahoo|0.6058914065361023|\n",
      "|  youtube|0.6052976250648499|\n",
      "|  hotmail|0.6032532453536987|\n",
      "|    likes|0.6031017899513245|\n",
      "|   tumblr|0.5892382264137268|\n",
      "|messenger|0.5810031890869141|\n",
      "|    gmail|0.5780516266822815|\n",
      "|  landing|0.5775303840637207|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synonyms = model.findSynonyms(\"facebook\", 20)   \n",
    "synonyms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk = crunchbase_desc.filter(lambda r: r[1]>=0 and r[1]<1000).collect()\n",
    "chunk = crunchbase_desc.take(50000)\n",
    "#chunk = crunchbase_desc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY = \"I like eating pizza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+--------------------+\n",
      "|index|        description|              tokens|   tokens_sw_removed|\n",
      "+-----+-------------------+--------------------+--------------------+\n",
      "|    1|I like eating pizza|[i, like, eating,...|[like, eating, pi...|\n",
      "+-----+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_df  = sc.parallelize([(1,SEARCH_QUERY)]).toDF(['index','description'])\n",
    "query_tok = regexTokenizer.transform(query_df)\n",
    "query_swr = swr.transform(query_tok)\n",
    "query_swr.show()\n",
    "query_vec = model.transform(query_swr)\n",
    "query_vec = query_vec.select('wordvectors').collect()[0][0]\n",
    "#query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----------------------------------------+------------------+\n",
      "|crunchbase_uuid                     |name                                    |similarity        |\n",
      "+------------------------------------+----------------------------------------+------------------+\n",
      "|7a3f6326-269d-fcd8-26b4-16cf8653a7dc|GoTime                                  |0.6140712711248749|\n",
      "|58e75fb8-524f-aad9-bc48-672703352691|Foodberry                               |0.6033352705245958|\n",
      "|ecde11d3-bd73-ff9e-3648-c4dcd388f95c|Zipityzap                               |0.6014549195836659|\n",
      "|5b818e0b-b9d5-44a0-0e4f-7557ea9626d1|Partins Jamaican Bakery & Grill         |0.5849417402210417|\n",
      "|d625185e-a39d-facd-808a-90b70b49c8f3|Attune Foods                            |0.584905530393183 |\n",
      "|25efac40-046d-26cb-7a7b-91c9b8909afb|Natural Balance Foods                   |0.5804848461050937|\n",
      "|380a50b2-e4bd-299c-10f9-ad1953639ba7|HealthySnacksGuide.com                  |0.5754325066092547|\n",
      "|819d117d-8cdf-78cf-3bd1-1fce59b380e7|Mister Softee China                     |0.5717697345734124|\n",
      "|68dd3433-e24d-1885-e987-d769d8ab9b21|Starbucks                               |0.5618208587227613|\n",
      "|b084dcd8-9f32-f7c3-e29f-2748eecb24b6|Perfect Fit Meals                       |0.5544019733021516|\n",
      "|5e9a751b-58ac-e3a1-0ebc-1411d88adc37|Le Gourmet TV                           |0.5538442222442022|\n",
      "|96aaa0b7-eed0-6d37-9331-7a8d962a434e|ElementBars.com                         |0.5498957581702311|\n",
      "|762cd069-f23c-110e-93fd-46a937158659|ChefMom.com                             |0.5477836465594396|\n",
      "|88343a3b-9739-17ce-d599-760cd42bee9f|BeefJack                                |0.5450598656278282|\n",
      "|32aca4ac-d747-c050-3f0b-6d3aa0999733|Revolution Foods                        |0.5384450848179203|\n",
      "|5f4b630b-be11-8c53-2eeb-128e67c25441|Asian Merchant Groceries & Gourmet Foods|0.536601090841774 |\n",
      "|b3b6a5cd-c5bf-5e5b-b8f2-a3ac1e3ad9d0|San Franola Granola                     |0.5354291064842249|\n",
      "|7a6b08d3-3abe-eb17-de74-f3cf11c6424a|Tiesta Tea                              |0.5333984514339923|\n",
      "|ec804e60-8250-4467-027e-71ac48ac38ca|Just Eat                                |0.5331662766638365|\n",
      "|3bf3b784-1ede-de5d-3514-79fd9fd67db4|Gormaya                                 |0.5298361959623376|\n",
      "+------------------------------------+----------------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sim_rdd = sc.parallelize((i[0], i[1], float(cossim(query_vec, i[2]))) for i in chunk)\n",
    "sim_df  = sqlContext.createDataFrame(sim_rdd).\\\n",
    "                   withColumnRenamed('_1', 'crunchbase_uuid').\\\n",
    "                   withColumnRenamed('_2', 'name').\\\n",
    "                   withColumnRenamed('_3', 'similarity').\\\n",
    "                   orderBy(\"similarity\", ascending = False)\n",
    "sim_df.show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2VecModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
