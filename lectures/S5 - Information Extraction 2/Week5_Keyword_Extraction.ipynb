{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction using TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank4Keyword():\n",
    "    \"\"\"Extract keywords from text\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 10 # iteration steps\n",
    "        self.node_weight = None # save keywords and its weight\n",
    "\n",
    "    \n",
    "    def set_stopwords(self, stopwords):  \n",
    "        \"\"\"Set stop words\"\"\"\n",
    "        for word in STOP_WORDS.union(set(stopwords)):\n",
    "            lexeme = nlp.vocab[word]\n",
    "            lexeme.is_stop = True\n",
    "    \n",
    "    def sentence_segment(self, doc, candidate_pos, lower):\n",
    "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                # Store words only with cadidate POS tag\n",
    "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "        \n",
    "    def get_vocab(self, sentences):\n",
    "        \"\"\"Get all tokens\"\"\"\n",
    "        vocab = OrderedDict()\n",
    "        i = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1\n",
    "        return vocab\n",
    "    \n",
    "    def get_token_pairs(self, window_size, sentences):\n",
    "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
    "        token_pairs = list()\n",
    "        for sentence in sentences:\n",
    "            for i, word in enumerate(sentence):\n",
    "                for j in range(i+1, i+window_size):\n",
    "                    if j >= len(sentence):\n",
    "                        break\n",
    "                    pair = (word, sentence[j])\n",
    "                    if pair not in token_pairs:\n",
    "                        token_pairs.append(pair)\n",
    "        return token_pairs\n",
    "        \n",
    "    def symmetrize(self, a):\n",
    "        return a + a.T - np.diag(a.diagonal())\n",
    "    \n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        \"\"\"Get normalized matrix\"\"\"\n",
    "        # Build matrix\n",
    "        vocab_size = len(vocab)\n",
    "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            g[i][j] = 1\n",
    "            \n",
    "        # Get Symmeric matrix\n",
    "        g = self.symmetrize(g)\n",
    "        \n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(g, axis=0)\n",
    "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
    "        \n",
    "        return g_norm\n",
    "\n",
    "    \n",
    "    def get_keywords(self, number=10):\n",
    "        \"\"\"Print top number keywords\"\"\"\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
    "        for i, (key, value) in enumerate(node_weight.items()):\n",
    "            print(key + ' - ' + str(value))\n",
    "            if i > number:\n",
    "                break\n",
    "        \n",
    "        \n",
    "    def analyze(self, text, \n",
    "                candidate_pos=['NOUN', 'PROPN'], \n",
    "                window_size=4, lower=False, stopwords=list()):\n",
    "        \"\"\"Main function to analyze text\"\"\"\n",
    "        \n",
    "        # Set stop words\n",
    "        self.set_stopwords(stopwords)\n",
    "        \n",
    "        # Pare text by spaCy\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Filter sentences\n",
    "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
    "        \n",
    "        # Build vocabulary\n",
    "        vocab = self.get_vocab(sentences)\n",
    "        \n",
    "        # Get token_pairs from windows\n",
    "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
    "        \n",
    "        # Get normalized matrix\n",
    "        g = self.get_matrix(vocab, token_pairs)\n",
    "        \n",
    "        # Initionlization for weight(pagerank value)\n",
    "        pr = np.array([1] * len(vocab))\n",
    "        \n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
    "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr)\n",
    "\n",
    "        # Get weight for each node\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = pr[index]\n",
    "        \n",
    "        self.node_weight = node_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_extractor = TextRank4Keyword()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix - 5.142884247372746\n",
      "Trainer - 3.104858212116699\n",
      "content - 2.8629801477461343\n",
      "percent - 2.6161740340469946\n",
      "Anthony - 1.9855734135916085\n",
      "streaming - 1.898886168209727\n",
      "Disney - 1.8977665674389792\n",
      "video - 1.8701483706096886\n",
      "year - 1.7830143220665544\n",
      "“ - 1.7500370343901208\n",
      "Thursday - 1.7118131407082973\n",
      "platform - 1.7019497829033114\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Disney will have a competitive advantage over Netflix when the entertainment conglomerate launches a competing video streaming platform later this year, according to Wall Street analyst David Trainer.\n",
    "\n",
    "″[Disney’s] got the ability to merchandise, which is another way to monetize content in a way that Netflix does not have,” Trainer said on CNBC’s “Closing Bell” Wednesday. He’s chief of the New Constructs research firm.\n",
    "\n",
    "Netflix increased its subscription prices Tuesday, sending the stock up 6.5 percent that day as well.\n",
    "\n",
    "However, Trainer called it a “key dilemma” for the company and it “makes their competitors more viable.” The dilemma, he explained, is that the streaming company relies too much on its subscribers to generate revenue.\n",
    "\n",
    "“It’s a Catch-22 for a business model that, when you look at the fundamentals, really just doesn’t work,” Trainer alleged.\n",
    "The Netflix price increase for U.S. subscribers ranges between 13 percent and 18 percent, which Victory Anthony of Aegis Capital sees as a positive, a view generally shared by much of the investment community.\n",
    "\n",
    "“It’s all profit for the price increase and so they can either use that to invest in more original content or they can let that drop down to their down to the bottom line,” Anthony said on “Squawk Alley” Thursday.\n",
    "\n",
    "Aegis put a hold on Neflix at current levels because it’s about 8 percent higher than Anthony’s price target of $325. The stock was trading steady around $351 midday Thursday, up more than 50 percent since the Christmas Eve washout. Netflix releases its fourth quarter earnings after the bell Thursday. Netflix last reported double-digit user growth, with 58 million U.S. and 78 million international subscribers.\n",
    "\n",
    "Original content aside, Netflix has built its large subscriber base, in part, on licensed content from a number of third-party TV and movie studios that plan to crowd into the video streaming market, which already includes other established online rivals such as Amazon and Hulu.\n",
    "\n",
    "Disney, which agreed to purchase Twenty-First Century Fox assets last summer, said it would pull its movies from Netflix when it launches Disney+ in late 2019. AT&T’s WarnerMedia announced in October it would release a platform in the fourth quarter of 2019. Apple could be dropping a service this year, Comcast’s NBCUniversal on Monday revealed plans for a free streaming program with ads slated for early 2020.\n",
    "\n",
    "New Constructs’ Trainer said Netflix is vulnerable because it’s a “one-trick pony” with an online distribution system that is not “defensible.” The company can keep growing its subscriber base, but it will need to address cash flow, he said.\n",
    "\n",
    "“You can count on one hand the number of firms that have, over time, successfully monetized original content. It’s an expensive, difficult proposition,” he argued. “Disney’s done it and part of the reason they’ve done [it] is because they’ve got better ways of monetizing.”\"\"\"\n",
    "tr4w = TextRank4Keyword()\n",
    "tr4w.analyze(text, candidate_pos = ['NOUN', 'PROPN',\"ADP\"], window_size=8, lower=False)\n",
    "tr4w.get_keywords(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another TextRank Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if you are getting an error in the block below, run the following command\n",
    "#!conda install -c anaconda nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_chunks(text, grammar=r'KT: {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}'):\n",
    "    import itertools, nltk, string\n",
    "    \n",
    "    # exclude candidates that are stop words or entirely punctuation\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenize, POS-tag, and chunk using regular expressions\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))\n",
    "    all_chunks = list(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent)) for tagged_sent in tagged_sents))\n",
    "    # join constituent chunk words into a single chunked phrase\n",
    "    candidates = [' '.join(word for word, pos, chunk in group).lower()\n",
    "                  for key, group in itertools.groupby(all_chunks, lambda word__pos__chunk: word__pos__chunk[2] != 'O') if key]\n",
    "\n",
    "    return [cand for cand in candidates\n",
    "            if cand not in stop_words and not all(char in punct for char in cand)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_words(text, good_tags=set(['JJ','JJR','JJS','NN','NNP','NNS','NNPS'])):\n",
    "    import itertools, nltk, string\n",
    "\n",
    "    # exclude candidates that are stop words or entirely punctuation\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenize and POS-tag words\n",
    "    tagged_words = itertools.chain.from_iterable(nltk.pos_tag_sents(nltk.word_tokenize(sent)\n",
    "                                                                    for sent in nltk.sent_tokenize(text)))\n",
    "    # filter on certain POS tags and lowercase all words\n",
    "    candidates = [word.lower() for word, tag in tagged_words\n",
    "                  if tag in good_tags and word.lower() not in stop_words\n",
    "                  and not all(char in punct for char in word)]\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_keyphrases_by_tfidf(texts, candidates='chunks'):\n",
    "    import gensim, nltk\n",
    "    \n",
    "    # extract candidates from each text in texts, either chunks or words\n",
    "    if candidates == 'chunks':\n",
    "        boc_texts = [extract_candidate_chunks(text) for text in texts]\n",
    "    elif candidates == 'words':\n",
    "        boc_texts = [extract_candidate_words(text) for text in texts]\n",
    "    # make gensim dictionary and corpus\n",
    "    dictionary = gensim.corpora.Dictionary(boc_texts)\n",
    "    corpus = [dictionary.doc2bow(boc_text) for boc_text in boc_texts]\n",
    "    # transform corpus with tf*idf model\n",
    "    tfidf = gensim.models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    return corpus_tfidf, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_keyphrases_by_textrank(text, n_keywords=0.05):\n",
    "    from itertools import takewhile, tee\n",
    "    import operator\n",
    "    import networkx, nltk\n",
    "    \n",
    "    # tokenize for all words, and extract *candidate* words\n",
    "    words = [word.lower()\n",
    "             for sent in nltk.sent_tokenize(text)\n",
    "             for word in nltk.word_tokenize(sent)]\n",
    "    candidates = extract_candidate_words(text)\n",
    "    # build graph, each node is a unique candidate\n",
    "    graph = networkx.Graph()\n",
    "    graph.add_nodes_from(set(candidates))\n",
    "    # iterate over word-pairs, add unweighted edges into graph\n",
    "    def pairwise(iterable):\n",
    "        \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n",
    "        a, b = tee(iterable)\n",
    "        next(b, None)\n",
    "        return zip(a, b)\n",
    "    for w1, w2 in pairwise(candidates):\n",
    "        if w2:\n",
    "            graph.add_edge(*sorted([w1, w2]))\n",
    "    # score nodes using default pagerank algorithm, sort by score, keep top n_keywords\n",
    "    ranks = networkx.pagerank(graph)\n",
    "    if 0 < n_keywords < 1:\n",
    "        n_keywords = int(round(len(candidates) * n_keywords))\n",
    "    word_ranks = {word_rank[0]: word_rank[1]\n",
    "                  for word_rank in sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)[:n_keywords]}\n",
    "                  #for word_rank in sorted(ranks.iteritems(), key=lambda x: x[1], reverse=True)[:n_keywords]}\n",
    "                  \n",
    "    #sorted(max_value_score.items(), key=operator.itemgetter(1), reverse=True)[:3]\n",
    "    keywords = set(word_ranks.keys())\n",
    "    # merge keywords into keyphrases\n",
    "    keyphrases = {}\n",
    "    j = 0\n",
    "    for i, word in enumerate(words):\n",
    "        if i < j:\n",
    "            continue\n",
    "        if word in keywords:\n",
    "            kp_words = list(takewhile(lambda x: x in keywords, words[i:i+10]))\n",
    "            avg_pagerank = sum(word_ranks[w] for w in kp_words) / float(len(kp_words))\n",
    "            keyphrases[' '.join(kp_words)] = avg_pagerank\n",
    "            # counter as hackish way to ensure merged keyphrases are non-overlapping\n",
    "            j = i + len(kp_words)\n",
    "            \n",
    "    return sorted(keyphrases.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #return sorted(keyphrases.iteritems(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('’', 0.039220978108779),\n",
       " ('netflix', 0.0350876915880868),\n",
       " ('“', 0.028118985335236824),\n",
       " ('”', 0.02776800702643579),\n",
       " ('’ trainer', 0.027651990850738942),\n",
       " ('“ disney ’', 0.0268940251718819),\n",
       " ('disney ’', 0.026281545090204438),\n",
       " ('” trainer', 0.021925505309567335),\n",
       " ('” thursday', 0.01998445696552105),\n",
       " ('percent', 0.018642227577005545),\n",
       " ('trainer', 0.01608300359269888),\n",
       " ('content', 0.015398075302705833),\n",
       " ('disney', 0.013342112071629868),\n",
       " ('subscribers', 0.01272545094646994),\n",
       " ('thursday', 0.012200906904606313),\n",
       " ('company', 0.012101345634754597)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Disney will have a competitive advantage over Netflix when the entertainment conglomerate launches a competing video streaming platform later this year, according to Wall Street analyst David Trainer.\n",
    "\n",
    "″[Disney’s] got the ability to merchandise, which is another way to monetize content in a way that Netflix does not have,” Trainer said on CNBC’s “Closing Bell” Wednesday. He’s chief of the New Constructs research firm.\n",
    "\n",
    "Netflix increased its subscription prices Tuesday, sending the stock up 6.5 percent that day as well.\n",
    "\n",
    "However, Trainer called it a “key dilemma” for the company and it “makes their competitors more viable.” The dilemma, he explained, is that the streaming company relies too much on its subscribers to generate revenue.\n",
    "\n",
    "“It’s a Catch-22 for a business model that, when you look at the fundamentals, really just doesn’t work,” Trainer alleged.\n",
    "The Netflix price increase for U.S. subscribers ranges between 13 percent and 18 percent, which Victory Anthony of Aegis Capital sees as a positive, a view generally shared by much of the investment community.\n",
    "\n",
    "“It’s all profit for the price increase and so they can either use that to invest in more original content or they can let that drop down to their down to the bottom line,” Anthony said on “Squawk Alley” Thursday.\n",
    "\n",
    "Aegis put a hold on Neflix at current levels because it’s about 8 percent higher than Anthony’s price target of $325. The stock was trading steady around $351 midday Thursday, up more than 50 percent since the Christmas Eve washout. Netflix releases its fourth quarter earnings after the bell Thursday. Netflix last reported double-digit user growth, with 58 million U.S. and 78 million international subscribers.\n",
    "\n",
    "Original content aside, Netflix has built its large subscriber base, in part, on licensed content from a number of third-party TV and movie studios that plan to crowd into the video streaming market, which already includes other established online rivals such as Amazon and Hulu.\n",
    "\n",
    "Disney, which agreed to purchase Twenty-First Century Fox assets last summer, said it would pull its movies from Netflix when it launches Disney+ in late 2019. AT&T’s WarnerMedia announced in October it would release a platform in the fourth quarter of 2019. Apple could be dropping a service this year, Comcast’s NBCUniversal on Monday revealed plans for a free streaming program with ads slated for early 2020.\n",
    "\n",
    "New Constructs’ Trainer said Netflix is vulnerable because it’s a “one-trick pony” with an online distribution system that is not “defensible.” The company can keep growing its subscriber base, but it will need to address cash flow, he said.\n",
    "\n",
    "“You can count on one hand the number of firms that have, over time, successfully monetized original content. It’s an expensive, difficult proposition,” he argued. “Disney’s done it and part of the reason they’ve done [it] is because they’ve got better ways of monetizing.”\"\"\"\n",
    "\n",
    "score_keyphrases_by_textrank(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
