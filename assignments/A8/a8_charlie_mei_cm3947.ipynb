{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595774425730",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 8\n",
    "by Charlie Mei cm3947\n",
    "\n",
    "Write a Python program based on the Week 8 class exercises (with Gensim, Scikit-Learn, or Spark MLLib), implementing LDA training and topic modeling on your dataset of deduplicated Webhose feeds\n",
    "\n",
    "- You may use LDA from Scikit-Learn, Gensim or Spark packages\n",
    "- Modify the values of min_df and max_df, max_features and max_iter (sklearn) to achieve best results\n",
    "- Your final submission should include:\n",
    "    - Jupyter Notebook or Python (.py) with your implementation\n",
    "    - Output showing set of n topic clusters with up to 10 keywords per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk, re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing my deduplicated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'unique_data.json'\n",
    "\n",
    "def parse_json_file(json_file):\n",
    "    with open(json_file) as f:\n",
    "        json_parsed = f.readlines()\n",
    "    json_data = [json.loads(row) for row in json_parsed]\n",
    "    return json_data\n",
    "\n",
    "mydata = parse_json_file(DATA_FILE)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [story['text'] for story in mydata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iOS 14 Will Support All iPhone Models That Run iOS 13, Including iPhone 6s Series: Report iOS 14 Will Support All iPhone Models That Run iOS 13, Including iPhone 6s Series: Report Apple will reportedly provide iOS 14 as the last major update on the iPhone 6s series and the iPhone SE. By Jagmeet Singh | Updated: 3 June 2020 12:28 IST Apple is hosting its WWDC on June 22 where we expect the formal launch of iOS 14 Highlights iOS 14 compatible devices list could include iPhone 6s and iPhone 6s Plus iPhone 7 series will reportedly receive updates until iOS 16 Apple is likely to release a beta version of iOS 14 following its launch\nApple will reportedly support iOS 14 for all iPhone models that can run iOS 13. This suggests that the Cupertino giant wouldn't make any changes in the list of compatible devices for the next iOS version from what it offered last year. The new development is, of course, good news for iPhone 6s and iPhone 6s Plus users as they both were launched with iOS 9 in September 2015. Apple is hosting its WWDC event later this month where we're likely to get an official word on the compatibility of iOS 14.\nIsraeli website The Verifier, on the basis of the early development code of iOS 14 and citing a person familiar with the development, wrote that the next iOS version will be compatible with all the iPhone models that were supported by iOS 13 . The list includes the iPhone 6s , iPhone 6s Plus , iPhone SE , iPhone 7 , iPhone 7 Plus , iPhone 8 , iPhone 8 Plus , iPhone X , iPhone XR , iPhone XS , and iPhone XS Max . The list also includes the newer devices, namely the iPhone 11 , iPhone 11 Pro , iPhone 11 Pro Max , and the iPhone SE (2020) , as well as the seventh-generation iPod touch.\nThe report also mentions that iOS 14 will be the last major update for the iPhone 6s series and the iPhone SE, while the iPhone 7 and iPhone 7 Plus will receive two additional updates after iOS 14. This suggests that the iPhone 7 series may be eligible for even iOS 16 in 2022. iOS 14 May Bring a Redesigned Multitasking Interface to iPhone\nApple hasn't provided any details about iOS 14. However, the company is expected to announce the new operating system for its mobile devices at WWDC 2020 on June 22 .\nIf the rollout proceeds as in the past, then iOS 14 would initially be offered in a beta version after the WWDC announcement later this month. It will then reach the stable release stage later this year — during the iPhone 12 launch, looking at the rollout in previous years.\nAn earlier report claimed that iOS 14 will come with a new Clips feature that would let users preview or test applications before installing them on their devices. The new iOS version is also rumoured to come with an enhanced iCloud Keychain and include redesigned wallpaper settings .\n\nin: News iPhone Looters Receives Being Tracked, Gets Warning From Apple After Opening Stolen Phones\niPhone LOOTERS BEING TRACKED – Following the death of George Floyd, several protests have erupted throughout the United States.\nPeople from different walks of life have banded together and protested against police brutality and injustice. However, there were several cases of bad actors capitalizing on the cause for their own gain.\nRioters began to burn down small businesses and looting became rampant. There was even a case where a policeman was caught looting Nike Shoes during a protest. Image from: Twitter\nMeanwhile, one of the stores heavily hit by the looting was Apple stores. With their range of premium products, they were a prime target for the hungry looters. However, little did they know that the phones could actually lead to their arrest.\nApple has been known to place proximity software on phones illegally taken from their stores. But, the software has seen little use as security within Apple stores are usually tight. Image from: Business Insider\nBut, this changed when people began looting for iPhones. However, after turning on the device, it simply said:\n“This device has been disabled and is being tracked”“Local authorities will be alerted”\nEven with this, there were still some mixed reactions on social media. Others have used this as an opportunity to promote their side business of unlocking iPhones. Meanwhile, others turned to memes to express their thoughts.\nThere were also people in social media who defended the looting. One user said that “stealing from a multi-billion-dollar company is never a loss” even if you don’t get money.\nWhat do you think about this issue? Leave a comment below!\nThanks for reading. We aim to provide our readers with the freshest and most in-demand content. Come back next time for the latest news here on Philnews.\n\n"
    }
   ],
   "source": [
    "# View some of the text\n",
    "for story in stories[:2]:\n",
    "    print(story)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Word Tokeenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_stories_lemma(story):\n",
    "    tokens = nltk.word_tokenize(story)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        token = token.replace(\"'s\", \" \").replace(\"n't\", \" not\").replace(\"'ve\", \" have\")\n",
    "        token = re.sub(r'[^a-zA-Z0-9 ]', '', token)\n",
    "        if token not in stopwords.words('english'):\n",
    "            filtered_tokens.append(token.lower())\n",
    "    \n",
    "    lemmas = [lmtzr.lemmatize(t, 'v') for t in filtered_tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an LDA creator\n",
    "\n",
    "The LDA will run on unigrams only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clstr_lda(num_topics, stories, min_df, max_df, max_iter, max_features=10, n_top_words=10):\n",
    "    tic = time.clock()\n",
    "\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    # Create word vectors from stories\n",
    "    tf_vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, max_features=max_features, tokenizer=tokenize_stories_lemma, ngram_range=(1, 1))\n",
    "    tf = tf_vectorizer.fit_transform(stories)\n",
    "    \n",
    "    toc = time.clock()\n",
    "    print('Tokenization finished in {} mins'.format((toc-tic)/60))\n",
    "\n",
    "    # Instantiate a LDA model\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, max_iter=max_iter, learning_method='batch', learning_offset=10, random_state=1)\n",
    "    # Using batch method since using on a massive dataset\n",
    "\n",
    "    print('Applying LDA model...')\n",
    "    tic = time.clock()\n",
    "    \n",
    "    lda.fit(tf)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "    topics = dict()\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        topics[topic_idx] = [tf_feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "        print(\"Topic \" + str(topic_idx))\n",
    "        print(\" | \".join([tf_feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]))\n",
    "    \n",
    "\n",
    "    toc = time.clock()\n",
    "    print('Time taken to run LDA: {} mins'.format((toc-tic)/60))\n",
    "\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 38.622762644999966 mins\nApplying LDA model...\nTopic 0\n5g | keyboard | table\nTopic 1\nhbo | aapl | remote\nTopic 2\ntrump | remote | table\nTopic 3\ntable | ratio | aapl\nTopic 4\nlaptop | keyboard | ratio\nTime taken to run LDA: 0.183505718333375 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['5g', 'keyboard', 'table'],\n 1: ['hbo', 'aapl', 'remote'],\n 2: ['trump', 'remote', 'table'],\n 3: ['table', 'ratio', 'aapl'],\n 4: ['laptop', 'keyboard', 'ratio']}"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "clstr_lda(5, stories, min_df=100, max_df=500, max_iter=10, max_features=10, n_top_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be too many topics as words such as ```keyboard``` and ```table``` show up in multiple topics. The keywords themselves perhaps could be more specific as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 38.33329671666667 mins\nApplying LDA model...\nTopic 0\nhbo | airpods | max\nTopic 1\nstock | quarter | rat\nTopic 2\ntrace | game | music\nTime taken to run LDA: 0.2743710083333326 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['hbo', 'airpods', 'max'],\n 1: ['stock', 'quarter', 'rat'],\n 2: ['trace', 'game', 'music']}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=300, max_df=1000, max_iter=10, n_top_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics still are not distinct, perhaps increasing the ```max_iter```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 24.76275367333333 mins\nApplying LDA model...\nTopic 0\nhbo | airpods | max\nTopic 1\nstock | quarter | rat\nTopic 2\ntrace | game | music\nTime taken to run LDA: 1.025736458333328 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['hbo', 'airpods', 'max'],\n 1: ['stock', 'quarter', 'rat'],\n 2: ['trace', 'game', 'music']}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=300, max_df=1000, max_iter=100, n_top_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing ```max_iter``` made no changes to the LDA results. How about making the keywords more specific?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 21.761033093333328 mins\nApplying LDA model...\nTopic 0\nairpods | max | battery\nTopic 1\nstock | quarter | rat\nTopic 2\ntrace | game | battery\nTime taken to run LDA: 0.17530960000000656 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['airpods', 'max', 'battery'],\n 1: ['stock', 'quarter', 'rat'],\n 2: ['trace', 'game', 'battery']}"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=500, max_df=1000, max_iter=10, n_top_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 22.070170145000006 mins\nApplying LDA model...\nTopic 0\nairpods | music | game\nTopic 1\nmax | se | galaxy\nTopic 2\nstock | quarter | rat\nTime taken to run LDA: 0.4987031899999996 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['airpods', 'music', 'game'],\n 1: ['max', 'se', 'galaxy'],\n 2: ['stock', 'quarter', 'rat']}"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=500, max_df=1000, max_iter=10, max_features=100, n_top_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keywords seem better but not fully informative of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 19.706789646666646 mins\nApplying LDA model...\nTopic 0\ngame | max | music\nTopic 1\nstock | quarter | rat\nTopic 2\ntrace | global | china\nTime taken to run LDA: 0.8385474150000239 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['game', 'max', 'music'],\n 1: ['stock', 'quarter', 'rat'],\n 2: ['trace', 'global', 'china']}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=500, max_df=1000, max_iter=10, max_features=500, n_top_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 20.28756733333333 mins\nApplying LDA model...\nTopic 0\nstock | quarter | rat\nTopic 1\ngame | macbook | se\nTopic 2\nhbo | trace | max\nTime taken to run LDA: 0.42144841833329943 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['stock', 'quarter', 'rat'],\n 1: ['game', 'macbook', 'se'],\n 2: ['hbo', 'trace', 'max']}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=200, max_df=1000, max_iter=10, max_features=100, n_top_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems better at applying keywords to topics. Three keywords appears too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenizing...\nTokenization finished in 20.310402481666642 mins\nApplying LDA model...\nTopic 0\nstock | quarter\nTopic 1\ngame | macbook\nTopic 2\nhbo | trace\nTime taken to run LDA: 0.47555513166668484 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['stock', 'quarter'], 1: ['game', 'macbook'], 2: ['hbo', 'trace']}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "clstr_lda(3, stories, min_df=200, max_df=1000, max_iter=10, max_features=100, n_top_words=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer appears appropriate but still need some optimizing for topics and maximum number of iterations.\n",
    "\n",
    "#### Optimizing for number of topics and max. iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=1000, min_df=200, max_features=100, tokenizer=tokenize_stories_lemma, ngram_range=(1, 1))\n",
    "tf = tf_vectorizer.fit_transform(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lda_model(tf, tf_vectorizer, num_topics, max_iter, n_top_words):\n",
    "    print('Applying LDA model...')\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, max_iter=max_iter, learning_method='batch', learning_offset=10, random_state=1)\n",
    "    lda.fit(tf)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "    topics = dict()\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        topics[topic_idx] = [tf_feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "\n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the unigram tokenizer, will see which combination of topics and keywords offer the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Applying LDA model...\nTopics for 3 topics and 3 keywords.\n{0: ['stock', 'quarter', 'rat'], 1: ['game', 'macbook', 'se'], 2: ['hbo', 'trace', 'max']}\n\n\nApplying LDA model...\nTopics for 3 topics and 5 keywords.\n{0: ['stock', 'quarter', 'rat', 'airpods', 'inc'], 1: ['game', 'macbook', 'se', 'galaxy', 'battery'], 2: ['hbo', 'trace', 'max', 'music', 'film']}\n\n\nApplying LDA model...\nTopics for 3 topics and 7 keywords.\n{0: ['stock', 'quarter', 'rat', 'airpods', 'inc', 'target', 'value'], 1: ['game', 'macbook', 'se', 'galaxy', 'battery', 'smart', 'camera'], 2: ['hbo', 'trace', 'max', 'music', 'film', 'exposure', 'podcast']}\n\n\nApplying LDA model...\nTopics for 5 topics and 3 keywords.\n{0: ['trace', 'airpods', 'china'], 1: ['macbook', 'table', 'microsoft'], 2: ['hbo', 'music', 'max'], 3: ['stock', 'quarter', 'rat'], 4: ['game', 'se', 'galaxy']}\n\n\nApplying LDA model...\nTopics for 5 topics and 5 keywords.\n{0: ['trace', 'airpods', 'china', 'podcast', 'government'], 1: ['macbook', 'table', 'microsoft', 'keyboard', 'mac'], 2: ['hbo', 'music', 'max', 'film', 'voice'], 3: ['stock', 'quarter', 'rat', 'inc', 'value'], 4: ['game', 'se', 'galaxy', 'camera', 'battery']}\n\n\nApplying LDA model...\nTopics for 5 topics and 7 keywords.\n{0: ['trace', 'airpods', 'china', 'podcast', 'government', 'exposure', 'reopen'], 1: ['macbook', 'table', 'microsoft', 'keyboard', 'mac', 'remote', 'laptop'], 2: ['hbo', 'music', 'max', 'film', 'voice', 'netflix', 'love'], 3: ['stock', 'quarter', 'rat', 'inc', 'value', 'billion', 'own'], 4: ['game', 'se', 'galaxy', 'camera', 'battery', 'card', 'smart']}\n\n\nApplying LDA model...\nTopics for 7 topics and 3 keywords.\n{0: ['trace', 'government', 'reopen'], 1: ['macbook', 'keyboard', 'tap'], 2: ['hbo', 'max', 'film'], 3: ['stock', 'quarter', 'rat'], 4: ['game', 'galaxy', 'camera'], 5: ['table', 'podcast', 'global'], 6: ['airpods', 'music', 'se']}\n\n\nApplying LDA model...\nTopics for 7 topics and 5 keywords.\n{0: ['trace', 'government', 'reopen', 'china', 'exposure'], 1: ['macbook', 'keyboard', 'tap', 'mac', 'smart'], 2: ['hbo', 'max', 'film', '135', 'netflix'], 3: ['stock', 'quarter', 'rat', 'inc', 'value'], 4: ['game', 'galaxy', 'camera', '5g', 'card'], 5: ['table', 'podcast', 'global', 'remote', 'microsoft'], 6: ['airpods', 'music', 'se', 'voice', 'sound']}\n\n\nApplying LDA model...\nTopics for 7 topics and 7 keywords.\n{0: ['trace', 'government', 'reopen', 'china', 'exposure', 'virus', 'trump'], 1: ['macbook', 'keyboard', 'tap', 'mac', 'smart', 'laptop', 'message'], 2: ['hbo', 'max', 'film', '135', 'netflix', 'id', 'plus'], 3: ['stock', 'quarter', 'rat', 'inc', 'value', 'own', 'average'], 4: ['game', 'galaxy', 'camera', '5g', 'card', 'tablet', 'brand'], 5: ['table', 'podcast', 'global', 'remote', 'microsoft', 'production', 'employees'], 6: ['airpods', 'music', 'se', 'voice', 'sound', 'audio', 'hear']}\n\n\n"
    }
   ],
   "source": [
    "num_topics = [3, 5, 7]\n",
    "n_top_words = [3, 5, 7]\n",
    "\n",
    "for topic in num_topics:\n",
    "    for keywords in n_top_words:\n",
    "        topics = test_lda_model(tf=tf, tf_vectorizer=tf_vectorizer, num_topics=topic, max_iter=10, n_top_words=keywords)\n",
    "        print('Topics for ' + str(topic) + ' topics and ' + str(keywords) + ' keywords.')\n",
    "        print(topics)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, the best LDA contains 7 topics and 7 keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying LDA model on 10 random articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_sample = random.sample(range(1, len(stories)), 10)\n",
    "\n",
    "random_10_stories = [stories[i] for i in random_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting LDA model...\n"
    }
   ],
   "source": [
    "print('Fitting LDA model...')\n",
    "lda = LatentDirichletAllocation(n_components=7, max_iter=10, learning_method='batch', learning_offset=10, random_state=1)\n",
    "lda_model = lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Applying LDA model...\n{0: ['trace', 'government', 'reopen', 'china', 'exposure', 'virus', 'trump'], 1: ['macbook', 'keyboard', 'tap', 'mac', 'smart', 'laptop', 'message'], 2: ['hbo', 'max', 'film', '135', 'netflix', 'id', 'plus'], 3: ['stock', 'quarter', 'rat', 'inc', 'value', 'own', 'average'], 4: ['game', 'galaxy', 'camera', '5g', 'card', 'tablet', 'brand'], 5: ['table', 'podcast', 'global', 'remote', 'microsoft', 'production', 'employees'], 6: ['airpods', 'music', 'se', 'voice', 'sound', 'audio', 'hear']}\n"
    }
   ],
   "source": [
    "topics = test_lda_model(tf, tf_vectorizer, 7, 10, 7)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_results = lda.fit_transform(tf)\n",
    "sample_stories_results = lda_results[random_sample,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             0         1         2         3         4         5         6\n8710  0.003868  0.003865  0.003867  0.003893  0.862413  0.118218  0.003875\n7772  0.424807  0.362566  0.015897  0.015925  0.148893  0.015903  0.016010\n7275  0.142857  0.142857  0.142857  0.142857  0.142857  0.142857  0.142857\n7759  0.071434  0.071429  0.071479  0.071429  0.071437  0.571348  0.071445\n6351  0.002133  0.414270  0.035311  0.002138  0.109000  0.002138  0.435009\n26    0.001318  0.001312  0.992106  0.001319  0.001314  0.001314  0.001317\n8933  0.938714  0.010225  0.010207  0.010206  0.010217  0.010205  0.010226\n2193  0.007940  0.007967  0.008008  0.063889  0.549055  0.007943  0.355197\n4715  0.010213  0.010269  0.753245  0.010215  0.010210  0.195640  0.010208\n8468  0.028719  0.230128  0.028575  0.626747  0.028584  0.028660  0.028587",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8710</th>\n      <td>0.003868</td>\n      <td>0.003865</td>\n      <td>0.003867</td>\n      <td>0.003893</td>\n      <td>0.862413</td>\n      <td>0.118218</td>\n      <td>0.003875</td>\n    </tr>\n    <tr>\n      <th>7772</th>\n      <td>0.424807</td>\n      <td>0.362566</td>\n      <td>0.015897</td>\n      <td>0.015925</td>\n      <td>0.148893</td>\n      <td>0.015903</td>\n      <td>0.016010</td>\n    </tr>\n    <tr>\n      <th>7275</th>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n    </tr>\n    <tr>\n      <th>7759</th>\n      <td>0.071434</td>\n      <td>0.071429</td>\n      <td>0.071479</td>\n      <td>0.071429</td>\n      <td>0.071437</td>\n      <td>0.571348</td>\n      <td>0.071445</td>\n    </tr>\n    <tr>\n      <th>6351</th>\n      <td>0.002133</td>\n      <td>0.414270</td>\n      <td>0.035311</td>\n      <td>0.002138</td>\n      <td>0.109000</td>\n      <td>0.002138</td>\n      <td>0.435009</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.001318</td>\n      <td>0.001312</td>\n      <td>0.992106</td>\n      <td>0.001319</td>\n      <td>0.001314</td>\n      <td>0.001314</td>\n      <td>0.001317</td>\n    </tr>\n    <tr>\n      <th>8933</th>\n      <td>0.938714</td>\n      <td>0.010225</td>\n      <td>0.010207</td>\n      <td>0.010206</td>\n      <td>0.010217</td>\n      <td>0.010205</td>\n      <td>0.010226</td>\n    </tr>\n    <tr>\n      <th>2193</th>\n      <td>0.007940</td>\n      <td>0.007967</td>\n      <td>0.008008</td>\n      <td>0.063889</td>\n      <td>0.549055</td>\n      <td>0.007943</td>\n      <td>0.355197</td>\n    </tr>\n    <tr>\n      <th>4715</th>\n      <td>0.010213</td>\n      <td>0.010269</td>\n      <td>0.753245</td>\n      <td>0.010215</td>\n      <td>0.010210</td>\n      <td>0.195640</td>\n      <td>0.010208</td>\n    </tr>\n    <tr>\n      <th>8468</th>\n      <td>0.028719</td>\n      <td>0.230128</td>\n      <td>0.028575</td>\n      <td>0.626747</td>\n      <td>0.028584</td>\n      <td>0.028660</td>\n      <td>0.028587</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(sample_stories_results, index=random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA model predicts that:\n",
    "\n",
    "- story 8710 belongs to topic 4\n",
    "- story 7772 belongs to topic 0\n",
    "- story 7275 could belong to any of the topics\n",
    "- story 7759 could belong to any of the topics\n",
    "- story 6351 belongs to topic 6\n",
    "- story 26 could belong to any of the topics\n",
    "- story 8933 belongs to topic 0\n",
    "- story 2193 belongs to topic 4\n",
    "- story 4715 belongs to topic 2\n",
    "- story 8468 belongs to topic 1."
   ]
  }
 ]
}