{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": 3
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python_defaultSpec_1594602413940",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "colab": {
      "name": "a6_charliemei_cm3947_part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZUK7NWz6wzh",
        "colab_type": "text"
      },
      "source": [
        "## Assignment 6 Part 2\n",
        "by Charlie Mei cm3947\n",
        "\n",
        "Write a Pyspark program based on the other provided Class Exercise, which:\n",
        "\n",
        "- Loads your previously obtained dataset of Webhose news articles into a Spark dataframe\n",
        "- Cleans up and tokenizes article bodies using the RegexTokenizer and Stopword remover functions provided in the Class Exercise\n",
        "- Trains a Word2Vec model based on the output column produced in step 2\n",
        "- Implements any sample search query, as shown in Class Exercise, and produces matching article titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI6kcWAv6wzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load(disable=['parser', 'tagger','ner'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW-nz41o7C8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9867da0d-cce9-4493-e25d-ba93c9eeb410"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7MB 53kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 38.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=b7a62d87e47d4cc2d34e0a3eaa27567fc54260a94192dccf82bc08ede3a04651\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOOQTv6L6wz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "sc = SparkContext() \n",
        "sqlContext = SQLContext(sc)\n",
        "from pyspark.mllib.linalg import Vector, Vectors\n",
        "from pyspark.mllib.clustering import LDA, LDAModel\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gcCmWxe6w0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanup_pretokenize(text):\n",
        "    #text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = text.replace(\"'s\", \" \")\n",
        "    text = text.replace(\"n't\", \" not \")\n",
        "    text = text.replace(\"'ve\", \" have \")\n",
        "    text = text.replace(\"'re\", \" are \")\n",
        "    text = text.replace(\"I'm\",\" I am \")\n",
        "    text = text.replace(\"you're\",\" you are \")\n",
        "    text = text.replace(\"You're\",\" You are \")\n",
        "    text = text.replace(\"-\",\" \")\n",
        "    text = text.replace(\"/\",\" \")\n",
        "    text = text.replace(\"(\",\" \")\n",
        "    text = text.replace(\")\",\" \")\n",
        "    text = text.replace(\"%\",\" percent \")\n",
        "    return text\n",
        "\n",
        "lmtzr = WordNetLemmatizer()\n",
        "def text_cleanup(row):\n",
        "    desc = row[2].strip().lower()\n",
        "    tokens = [w.lemma_ for w in nlp(cleanup_pretokenize(desc))]\n",
        "    tokens = [token for token in tokens if token.isalpha()]\n",
        "    tokens = [token for token in tokens if len(token) > 3]\n",
        "    #tokens = [lmtzr.lemmatize(token,'v') for token in tokens]\n",
        "    row[2] = ' '.join(tokens)\n",
        "    return row\n",
        "\n",
        "regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'text', outputCol = 'tokens')\n",
        "swr = StopWordsRemover(inputCol = 'tokens', outputCol = 'tokens_sw_removed')\n",
        "\n",
        "def cossim(v1, v2): \n",
        "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / (np.sqrt(np.dot(v2, v2))+.1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPStS6Ie6w0e",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the Webhose Dataset and Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "IkUHLEGR6w0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data into Spark Dataframe\n",
        "crunch_df = sqlContext.read.option('header', 'true').option('delimiter', ',').option('inferSchema', 'true').json('webhose_netflix.json')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "vimO3HbJ6w0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "48ee6cf8-3cc8-41d7-b007-16ef8bb9258f"
      },
      "source": [
        "crunchbase_data = crunch_df['uuid','title','text']\n",
        "\n",
        "cols = [0, 1, 2]\n",
        "crunchbase_rdd = crunchbase_data.select('*').rdd.map(lambda row: [row[i] for i in cols]).filter(lambda row: row[2] is not None)\n",
        "crunchbase_df = sqlContext.createDataFrame(crunchbase_rdd, ['uuid', 'title', 'text'])\n",
        "crunchbase_df.show(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                uuid|               title|                text|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|f890670c140631022...|13 Reasons Why: T...|The controversial...|\n",
            "|f1da1d6c5ddf6b095...|Judge gives contr...|A federal judge i...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "VXjlEpfe6w1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "490f3f29-029d-475d-d546-5f0c0337a36d"
      },
      "source": [
        "# Tokenize and remove stopwords\n",
        "df_tokens = regexTokenizer.transform(crunchbase_df)\n",
        "desc_swr = swr.transform(df_tokens)\n",
        "desc_swr.show(3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                uuid|               title|                text|              tokens|   tokens_sw_removed|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|f890670c140631022...|13 Reasons Why: T...|The controversial...|[the, controversi...|[controversial, 1...|\n",
            "|f1da1d6c5ddf6b095...|Judge gives contr...|A federal judge i...|[a, federal, judg...|[federal, judge, ...|\n",
            "|f431c194e4eddacdd...|A TV reboot of Bo...|WhatsApp If you e...|[whatsapp, if, yo...|[whatsapp, enjoye...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjTxmyuA6w1X",
        "colab_type": "text"
      },
      "source": [
        "#### Training a Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShA5XExK6w1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a44372cf-59b4-4cb6-d330-6416a8c58a70"
      },
      "source": [
        "# Train a word2vec model\n",
        "word2vec = Word2Vec(vectorSize = 300, minCount = 5, inputCol = 'tokens_sw_removed', outputCol = 'wordvectors')\n",
        "model = word2vec.fit(desc_swr)\n",
        "wordvectors = model.transform(desc_swr)\n",
        "#wordvectors.select('wordvectors').show(1, truncate = True)\n",
        "crunchbase_desc = wordvectors.select('uuid','title','wordvectors').rdd.toDF()\n",
        "crunchbase_desc.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                uuid|               title|         wordvectors|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|f890670c140631022...|13 Reasons Why: T...|[-0.0801881681807...|\n",
            "|f1da1d6c5ddf6b095...|Judge gives contr...|[-0.0088495124698...|\n",
            "|f431c194e4eddacdd...|A TV reboot of Bo...|[-0.0838881237240...|\n",
            "|5930a57af03089f5d...|2-Pack: Ideaworks...|[-0.0542835764252...|\n",
            "|050149948217f53d4...|Already-Obese Ave...|[-0.0393892194748...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsnZvXCy6w1n",
        "colab_type": "text"
      },
      "source": [
        "#### Searching for matching articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KIP5vCm6w1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunk = crunchbase_desc.take(50000)\n",
        "def search_for_similar_articles(SEARCH_QUERY):\n",
        "    # Turn query into a word vector\n",
        "    query_df  = sc.parallelize([(1,SEARCH_QUERY)]).toDF(['index','text'])\n",
        "    query_tok = regexTokenizer.transform(query_df)\n",
        "    query_swr = swr.transform(query_tok)\n",
        "    query_vec = model.transform(query_swr)\n",
        "    query_vec = query_vec.select('wordvectors').collect()[0][0]\n",
        "\n",
        "    # Find similar articles\n",
        "    sim_rdd = sc.parallelize((i[0], i[1], float(cossim(query_vec, i[2]))) for i in chunk)\n",
        "    sim_df  = sqlContext.createDataFrame(sim_rdd).\\\n",
        "                   withColumnRenamed('_1', 'crunchbase_uuid').\\\n",
        "                   withColumnRenamed('_2', 'name').\\\n",
        "                   withColumnRenamed('_3', 'similarity').\\\n",
        "                   orderBy(\"similarity\", ascending = False)\n",
        "    return sim_df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwrJyerB995Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ad796499-be28-4176-8ee2-87c6ba5546cb"
      },
      "source": [
        "sim_df = search_for_similar_articles(SEARCH_QUERY = '13 Reasons Why')\n",
        "sim_df.show(20, truncate=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------+-------------------------------------------------------------------------------------------------------------------+------------------+\n",
            "|crunchbase_uuid                         |name                                                                                                               |similarity        |\n",
            "+----------------------------------------+-------------------------------------------------------------------------------------------------------------------+------------------+\n",
            "|1ac02b291edbd50ab93054d6a47cea96339ed17f|Watch the Trailer for the Final Season of '13 Reasons Why'!                                                        |0.6813239495615256|\n",
            "|b27f092a2c9be2a7150a912639f9791a2381eb74|Netflix’s 13 Reasons Why Final Season Trailer Released                                                             |0.628123089230771 |\n",
            "|ffe5e336bfbd2663e10900cbaf176ba0f3eed48a|13 Reasons Why: The Final Season gets new trailer from Netflix                                                     |0.6275335687473739|\n",
            "|cf9724da9b4d27cf34df5300fec45a97f4af9e9f|What happened in Netflix’s 13 Reasons Why season 3?                                                                |0.5707368645600297|\n",
            "|bfb799f0466b20013b880ba06e23808486467e67|13 Reasons Why Final Season Trailer Does Not Impress Much, Receives Mixed Response on Twitter                      |0.5664743509162574|\n",
            "|b31aafa11cac77ceb9b3f8d825dcfbc32719d423|Web Series, Bollywood Hollywood movies Netflix, Amazon Prime Video, Hotstar, SonyLIV, ALTBalaji, ZEE5 free online  |0.5602314704896705|\n",
            "|5693c9c9658fa07597d77fdd93cd4298491329c8|WATCH: Netflix Releases New Trailer For Final Season Of ’13 Reasons Why’                                           |0.559747895107094 |\n",
            "|5cb88ef5db3235031fb32b27a7e5668ff1863c7c|Final Season of 13 Reasons Why to premiere on Netflix on 5th June                                                  |0.5577503106519333|\n",
            "|79b20cd397e7f42b86310221f7aede2d587d750c|(Official Trailer) 13 Reasons Why: Final Season – Netflix                                                          |0.5538137045039375|\n",
            "|23b36b4eaa31b92c5a6633f03968de3250cea0da|Everything Coming To Netflix Australia In June 2020                                                                |0.5533831373069367|\n",
            "|19cfd37ffafc629b07d36489eb5cf23a89248b7f|Netflix’s 13 Reasons Why most controversial moments revealed                                                       |0.5433126441826771|\n",
            "|0129933b08cbd1229f7e0105480b74cc5886053f|What's coming and going from Hulu, Netflix and Amazon in June 2020                                                 |0.531819574236632 |\n",
            "|c96d61287a254bf9f9bb70714586e5e61990f108|What's coming and going from Hulu, Netflix and Amazon in June 2020 | Movies | napavalleyregister.com               |0.5305822472812566|\n",
            "|15034bc9dbe8794117322c0cdd4b9519b1d61d17|'13 Reasons Why' Releases Yearbook Photos For New Cast Portraits                                                   |0.5295086157095751|\n",
            "|9f34a2989ae60faf2e8886350f081de848a2b0de|13 Reasons Why Season 4 Trailer and Release Date                                                                   |0.5293768583572398|\n",
            "|9d1fab1827c5313bcc9e844b258be6df600d5fb1|Everything New on Netflix in June: Dark Season 3, 13 Reasons Why Season 4, and More                                |0.5237500064321586|\n",
            "|ef10a86e4f1a48ba45fcbf4318ec191d24057773|5 Netflix shows to snuggle up to this June                                                                         |0.5208151864537667|\n",
            "|ed7890b15861fd3d8cc2ad6011d7aa0fe5da6032|The trailer for the final season of '13 Reasons Why' teases that everyone's big secret is going to finally come out|0.5199610114522644|\n",
            "|ab878b0c3f5b677c2ae8f65affadc2d89680ceaf|New on Netflix (June 2020): All the movies and shows arriving this month | GamesRadar+                             |0.5198326638110503|\n",
            "|8520ba836e805b49ddec3e69ba8d23e347609e78|Everything Coming To Netflix in June – Eagle 104                                                                   |0.5192689488993207|\n",
            "+----------------------------------------+-------------------------------------------------------------------------------------------------------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}